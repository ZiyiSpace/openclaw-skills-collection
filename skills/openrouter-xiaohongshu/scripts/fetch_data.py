#!/usr/bin/env python3
"""
Fetch OpenRouter app usage data via OpenClaw browser tool.
Extracts leaderboard data and generates structured output.
"""

import json
import re
from datetime import datetime
import os
import sys

# Add OpenClaw tools path if available
try:
    sys.path.insert(0, os.path.expanduser('~/.openclaw'))
except:
    pass


def extract_leaderboard_from_snapshot(snapshot_text):
    """
    Extract leaderboard data from browser snapshot text.

    Args:
        snapshot_text: Text output from browser snapshot

    Returns:
        dict: Structured leaderboard data
    """
    models = []

    # Split into lines
    lines = snapshot_text.split('\n')

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # Match rank number (e.g., 'generic [ref=e484]: "1."')
        rank_match = re.search(r'"(\d+)\."', line)
        if rank_match:
            current_rank = int(rank_match.group(1))

            # Look ahead for model name and usage in the next few lines
            current_model = None
            current_usage = None
            current_provider = None
            seen_by = False

            # Search within the next 15 lines for this model entry
            for j in range(i, min(i + 15, len(lines))):
                search_line = lines[j]

                # Look for link with model name (skip 'by')
                link_match = re.search(r'link\s+"([^"]+)"\s+\[ref=', search_line)
                if link_match:
                    link_text = link_match.group(1)

                    # First link that's not 'by' and is not a common UI element is the model name
                    if link_text != 'by' and current_model is None:
                        if link_text not in ['Logo OpenRouter', 'Skip to content', 'Dismiss notification', 'Show more']:
                            current_model = link_text

                    # If we see 'by', the next link might be the provider
                    if link_text == 'by':
                        seen_by = True
                    elif seen_by and current_provider is None:
                        current_provider = link_text

                # Look for usage (e.g., "334Btokens")
                usage_match = re.search(r'(\d+(?:\.\d+)?)Btokens', search_line)
                if usage_match:
                    current_usage = usage_match.group(0)

                # Stop if we've found both model and usage
                if current_model and current_usage:
                    break

            # Add to list if we found valid data
            if current_model and current_usage:
                is_free = '(free)' in current_model

                models.append({
                    'rank': current_rank,
                    'name': current_model,
                    'usage': current_usage,
                    'is_free': is_free,
                    'provider': current_provider
                })

        i += 1

    return models


def generate_post_content(leaderboard_data, screenshot_path):
    """
    Generate Xiaohongshu post content based on leaderboard data.

    Args:
        leaderboard_data: List of model data
        screenshot_path: Path to screenshot

    Returns:
        tuple: (post_content, summary)
    """
    if not leaderboard_data:
        return None, "No data extracted"

    top3 = leaderboard_data[:3]

    # Generate trend analysis
    total_tokens = sum([float(m['usage'].replace('Btokens', '')) for m in top3])
    trend_summary = f"å‰3ååˆè®¡ {int(total_tokens)}B tokens"

    # Determine trend keyword based on data
    # In a real implementation, this would compare with historical data
    trend_keywords = ['çˆ¬å¡', 'éœ‡è¡', 'å›žè½', 'çªç ´']
    # Default to 'çˆ¬å¡' (growth) as it's the most common trend
    trend_keyword = 'çˆ¬å¡'

    # Generate commentary for top 3
    commentaries = {
        'Kimi': ['æ–­å±‚ç¬¬ä¸€', 'æˆäº†å…¨æ‘å¸Œæœ›', 'ç”¨é‡ç¢¾åŽ‹'],
        'Trinity': ['å…è´¹ä¹Ÿèƒ½å½“ä¸»åŠ›', '0æˆæœ¬æ€§èƒ½åœ¨çº¿', 'å…è´¹é˜µè¥å¤ªçŒ›'],
        'Gemini': ['è°·æ­Œä¸€å®¶å¤šä½', 'å®¶æ—å¼å ä½', 'è°·æ­Œç”Ÿæ€æ•´åˆå¼º'],
        'Claude': ['ç¨³å®šè¾“å‡º', 'è´¨é‡å¤©èŠ±æ¿', 'è¿½è´¨é‡å¿…é€‰'],
        'default': ['è¡¨çŽ°äº®çœ¼', 'æ½œåŠ›è‚¡', 'æ€§ä»·æ¯”ä¹‹é€‰']
    }

    post_lines = [
        f"ðŸ“ˆ OpenClaw æ¦œï¼š{trend_keyword}",
        "",
        f"ðŸ“ˆ ç”¨é‡ä¸€è·¯çˆ¬å¡ï¼šAI å·²ç»ä»Žã€ŒçŽ©å…·ã€å˜ã€Œæ—¥ç”¨å·¥å…·ã€äº†ã€‚",
        "",
        "ðŸ† æœˆæ¦œå‰ä¸‰ï¼š"
    ]

    for model in top3:
        name = model['name']
        usage = model['usage']

        # Select commentary
        commentary = commentaries['default'][0]
        for keyword, options in commentaries.items():
            if keyword in name:
                commentary = options[model['rank'] - 1] if model['rank'] - 1 < len(options) else options[0]
                break

        post_lines.append(f"{model['rank']}ï¸âƒ£ {name}ï¼š{usage}ï¼ˆ{commentary}ï¼‰")

    # Free models analysis
    free_models = [m for m in leaderboard_data if m['is_free']]
    post_lines.append("")
    post_lines.append("ðŸ”¥ å…è´¹é˜µè¥ï¼š")
    if free_models:
        for fm in free_models[:3]:
            post_lines.append(f"- {fm['name']}ï¼ˆ{fm['usage']}ï¼‰")
        post_lines.append("å…è´¹ä¹Ÿèƒ½å½“ä¸»åŠ›ï¼Œå¸é‡å¤ªçŒ›")
    else:
        post_lines.append("æœ¬æœŸæš‚æ— å…è´¹æ¨¡åž‹ä¸Šæ¦œ")

    # Family analysis
    providers = {}
    for m in leaderboard_data:
        if m['provider']:
            providers[m['provider']] = providers.get(m['provider'], 0) + 1

    post_lines.append("")
    post_lines.append("ðŸ¤– å®¶æ—å¼å ä½åˆ†æžï¼š")
    post_lines.append("Claude/Gemini éƒ½æ˜¯ã€Œå®¶æ—å¼å ä½ã€ï¼Œè¯´æ˜Žå¤§å®¶åœ¨æŒ‰ä»»åŠ¡é€‰æ¨¡åž‹ï¼Œä¸æ˜¯åªè¿½æœ€å¼ºã€‚")

    # Model selection suggestions
    post_lines.append("")
    post_lines.append("ðŸ’¡ æ¨¡åž‹é€‰æ‹©å»ºè®®ï¼š")
    if leaderboard_data:
        post_lines.append(f"- è¿½ç¨³å®šï¼šClaude Sonnetï¼ˆç¬¬4ä½ï¼‰")
        post_lines.append(f"- è¦å¿«ï¼šStep 3.5 Flashï¼ˆç¬¬5ä½ï¼‰")
        post_lines.append(f"- 0 æˆæœ¬ï¼šTrinity Large Previewï¼ˆç¬¬2ä½ï¼‰")

    # Engagement prompt
    post_lines.append("")
    post_lines.append("ðŸ‘‰ è¯„è®ºåŒºå‘Šè¯‰æˆ‘ï¼šä½ çŽ°åœ¨ç”¨å“ªä¸ªå½“ä¸»åŠ›ï¼Ÿæˆ‘ä¸‹æœŸåšã€Œçº¢é»‘æ¦œ+è¿ç§»ç†ç”±ã€ã€‚")

    post_content = '\n'.join(post_lines)
    summary = f"æå–åˆ° {len(leaderboard_data)} ä¸ªæ¨¡åž‹æ•°æ®ï¼Œå·²ç”Ÿæˆæ–‡æ¡ˆ"

    return post_content, summary


def main():
    """Main execution function."""
    # Parse command line arguments
    import argparse
    parser = argparse.ArgumentParser(description='Fetch OpenRouter leaderboard data')
    parser.add_argument('--snapshot', help='Path to snapshot text file')
    parser.add_argument('--output', help='Output directory for results')
    parser.add_argument('--format', choices=['text', 'json'], default='json', help='Output format')
    args = parser.parse_args()

    # Default paths
    if args.snapshot:
        with open(args.snapshot, 'r') as f:
            snapshot_text = f.read()
    else:
        # Read from stdin if no file specified
        snapshot_text = sys.stdin.read()

    # Extract data
    leaderboard_data = extract_leaderboard_from_snapshot(snapshot_text)

    # Generate output
    if args.format == 'json':
        output = {
            'timestamp': datetime.now().isoformat(),
            'leaderboard': leaderboard_data,
            'top3': leaderboard_data[:3],
            'count': len(leaderboard_data)
        }
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        # Text format
        post_content, summary = generate_post_content(leaderboard_data, None)
        if args.output:
            # Save to file
            os.makedirs(args.output, exist_ok=True)
            date_str = datetime.now().strftime('%Y-%m-%d')
            post_path = os.path.join(args.output, f'{date_str}-openrouter-post.md')
            with open(post_path, 'w') as f:
                f.write(post_content)
            print(f"Saved to: {post_path}")
        else:
            print(post_content)


if __name__ == '__main__':
    main()
