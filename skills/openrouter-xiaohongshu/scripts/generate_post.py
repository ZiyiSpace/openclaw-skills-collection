#!/usr/bin/env python3
"""
Main script to generate OpenRouter daily post for Xiaohongshu.
Usage: Called from OpenClaw session or cron.
"""

import json
import subprocess
import sys
import os
from datetime import datetime


def get_base_dir():
    """Get skill base directory."""
    return os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


def run_fetch_data(snapshot_text, output_dir=None):
    """
    Run fetch_data.py to extract leaderboard data.

    Args:
        snapshot_text: Browser snapshot text
        output_dir: Output directory for results

    Returns:
        dict: Extracted data and generated post
    """
    base_dir = get_base_dir()
    script_path = os.path.join(base_dir, 'scripts', 'fetch_data.py')

    # Run the fetch script with snapshot data
    cmd = [sys.executable, script_path, '--format', 'json']

    if output_dir:
        cmd.extend(['--output', output_dir])

    result = subprocess.run(
        cmd,
        input=snapshot_text,
        capture_output=True,
        text=True
    )

    if result.returncode != 0:
        raise Exception(f"fetch_data.py failed: {result.stderr}")

    return json.loads(result.stdout)


def generate_post_content(leaderboard_data):
    """
    Generate complete post content with enhanced analysis.

    Args:
        leaderboard_data: Extracted leaderboard data

    Returns:
        str: Formatted post content
    """
    if not leaderboard_data or not leaderboard_data.get('leaderboard'):
        return None

    all_models = leaderboard_data['leaderboard']
    top5 = all_models[:5]
    free_models = [m for m in all_models if m['is_free']]

    # Get date
    today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')

    # Generate post
    post_lines = [
        f"ðŸ“Š {today} OpenClaw æ¨¡åž‹æŽ’è¡Œæ¦œ",
        "",
        "ðŸ“‹ æŽ’å | æ¨¡åž‹ | æ¶ˆè€—é‡ | è¯„ä»·",
        "---" * 15
    ]

    # Generate commentary for top 5
    for model in top5:
        name = model['name']
        usage = model['usage']

        # Generate emoji and commentary
        if model['rank'] == 1:
            emoji = 'ðŸ‘‘'
            if 'Kimi' in name:
                commentary = 'æ–­å±‚çŽ‹è€…ï¼Œç»å¯¹ä¸»åŠ›'
            else:
                commentary = 'æ¦œé¦–éœ¸ä¸»'
        elif model['rank'] == 2:
            emoji = 'ðŸ¥ˆ'
            commentary = 'å¼ºåŠ›äºšå†›'
        elif model['rank'] == 3:
            emoji = 'ðŸ¥‰'
            commentary = 'ç¨³å±…ä¸‰ç”²'
        elif model['is_free']:
            emoji = 'ðŸ”¥'
            commentary = 'å…è´¹é»‘é©¬ï¼Œå¸é‡æƒŠäºº'
        elif 'Kimi' in name:
            emoji = 'ðŸŒŸ'
            commentary = 'ç¨³å®šè¾“å‡º'
        elif 'Claude' in name:
            emoji = 'ðŸ’Ž'
            commentary = 'è´¨é‡å¤©èŠ±æ¿'
        elif 'Gemini' in name:
            emoji = 'ðŸŒˆ'
            commentary = 'è°·æ­Œç”Ÿæ€å¼º'
        elif 'Step' in name:
            emoji = 'âš¡'
            commentary = 'æŽ¨ç†é€Ÿåº¦å¿«'
        elif 'Pony' in name:
            emoji = 'ðŸ´'
            commentary = 'ç¤¾åŒºå£ç¢‘é»‘é©¬'
        elif 'DeepSeek' in name:
            emoji = 'ðŸ”'
            commentary = 'æ€§ä»·æ¯”ä¹‹é€‰'
        elif 'Grok' in name:
            emoji = 'ðŸ¦'
            commentary = 'é©¬æ–¯å…‹å‡ºå“'
        else:
            emoji = 'ðŸ“ˆ'
            commentary = 'è¡¨çŽ°äº®çœ¼'

        post_lines.append(f"{emoji} ç¬¬{model['rank']}å | {name} | {usage} | {commentary}")

    # Free models section
    if free_models:
        post_lines.append("")
        post_lines.append("ðŸ”¥ å…è´¹é˜µè¥å¤ªçŒ›ï¼š")
        for fm in free_models[:3]:
            post_lines.append(f"â€¢ {fm['name']}ï¼š{fm['usage']}ï¼ˆç¬¬{fm['rank']}ä½ï¼‰")

    # Deep analysis report
    post_lines.append("")
    post_lines.append("ðŸ“ æ·±åº¦åˆ†æžæŠ¥å‘Šï¼š")

    # Analysis 1: Top model analysis
    top_model = all_models[0]
    post_lines.append("")
    post_lines.append("1ï¸âƒ£ ç¨³åé’“é±¼å°çš„çŽ‹è€…")
    post_lines.append(f"ðŸ‘‘ {top_model['name']}ï¼š{top_model['usage']}")
    if 'Kimi' in top_model['name']:
        post_lines.append("èƒŒæ™¯ï¼šMoonshot AIï¼ˆæœˆä¹‹æš—é¢ï¼‰çš„æ——èˆ°æ¨¡åž‹ã€‚")
        post_lines.append("åˆ†æžï¼šå½“å…¶ä»–æ¨¡åž‹è¿˜åœ¨äº‰å¤ºã€Œè€äºŒè€ä¸‰ã€æ—¶ï¼ŒKimi K2.5 ä¾ç„¶å æ®æ¦œé¦–ï¼Œæ¯”ç¬¬äºŒåé«˜å‡ºä¸€å€å¤šã€‚è¯´æ˜Žå®ƒå·²ç»æˆä¸ºäº†å¤§å¤šæ•°ç”¨æˆ·çš„ã€Œæ—¥ç”¨ä¸»åŠ›ï¼ˆDaily Driverï¼‰ã€ï¼Œä¸ä»…æ˜¯å°é²œï¼Œè€Œæ˜¯çœŸæ­£èžå…¥äº†å·¥ä½œæµã€‚")
    elif 'Trinity' in top_model['name']:
        post_lines.append("èƒŒæ™¯ï¼šArcee AI çš„å…è´¹é¢„è§ˆæ¨¡åž‹ã€‚")
        post_lines.append("åˆ†æžï¼šå…è´¹æ¨¡åž‹ç™»é¡¶ï¼Œè¯´æ˜Žç”¨æˆ·å¯¹ã€Œ0 æˆæœ¬ä¸”å¼ºã€çš„éœ€æ±‚å¼ºçƒˆã€‚ç”¨æˆ·å¿ è¯šåº¦æžä½Žï¼Œä¸€æ—¦æœ‰æ›´å¥½çš„å…è´¹æ›¿ä»£å“ï¼Œä¼šç«‹å³è¿ç§»ã€‚")
    else:
        post_lines.append(f"èƒŒæ™¯ï¼š{top_model['name']} æ˜¯æœ¬æœŸæ¦œå•çš„æ¦œé¦–ã€‚")
        post_lines.append("åˆ†æžï¼šå‡­å€Ÿå‡ºè‰²çš„æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒï¼ŒèŽ·å¾—äº†ç”¨æˆ·çš„å¹¿æ³›è®¤å¯ï¼Œæˆä¸ºå½“å‰çš„ä¸»åŠ›é€‰æ‹©ã€‚")

    # Analysis 2: Free models phenomenon
    if free_models:
        post_lines.append("")
        post_lines.append("2ï¸âƒ£ å…è´¹é˜µè¥çš„å†…å·")
        post_lines.append(f"ðŸ”¥ æœ¬æœŸæœ‰ {len(free_models)} ä¸ªå…è´¹æ¨¡åž‹ä¸Šæ¦œï¼š")
        for fm in free_models:
            post_lines.append(f"â€¢ {fm['name']}ï¼ˆç¬¬{fm['rank']}ä½ï¼‰")
        post_lines.append("åˆ†æžï¼š2026 å¹´åˆçš„ä¸€ä¸ªæ ¸å¿ƒçŽ°è±¡ â€”â€”ã€Œå…è´¹ä¸”å¼ºã€çš„æ¨¡åž‹æ­£åœ¨ç–¯ç‹‚å†…å·ã€‚ç”¨æˆ·æ­£åœ¨å¤§é‡æµ‹è¯•è¿™äº›å…è´¹æ¨¡åž‹çš„è¾¹ç•Œï¼Œå®ƒä»¬çš„æµé‡å¢žé•¿é€Ÿåº¦è¿œè¶…ä»˜è´¹æ¨¡åž‹ã€‚")

    # Analysis 3: Family model positioning
    provider_counts = {}
    for m in all_models[:10]:
        # Extract provider from model name or use default
        if 'Kimi' in m['name']:
            provider = 'Moonshot AI'
        elif 'Claude' in m['name']:
            provider = 'Anthropic'
        elif 'Gemini' in m['name']:
            provider = 'Google'
        elif 'Step' in m['name']:
            provider = 'StepFun'
        elif 'Pony' in m['name']:
            provider = 'OpenRouter'
        elif 'DeepSeek' in m['name']:
            provider = 'DeepSeek'
        elif 'Grok' in m['name']:
            provider = 'xAI'
        elif 'Trinity' in m['name']:
            provider = 'Arcee AI'
        else:
            provider = m.get('provider', 'Unknown')

        provider_counts[provider] = provider_counts.get(provider, 0) + 1

    family_models = {k: v for k, v in provider_counts.items() if v > 1}
    if family_models:
        post_lines.append("")
        post_lines.append("3ï¸âƒ£ å®¶æ—å¼å ä½åˆ†æž")
        post_lines.append("ðŸ¤– å¤šä¸ªæ¨¡åž‹æ¥è‡ªåŒä¸€åŽ‚å•†ï¼š")
        for provider, count in family_models.items():
            post_lines.append(f"â€¢ {provider}ï¼š{count} ä¸ªæ¨¡åž‹")
        post_lines.append("åˆ†æžï¼šè¿™è¯´æ˜Žå¤§å®¶åœ¨ã€ŒæŒ‰ä»»åŠ¡é€‰æ¨¡åž‹ã€ï¼Œä¸æ˜¯åªè¿½æœ€å¼ºã€‚ä¸åŒçš„æ¨¡åž‹é’ˆå¯¹ä¸åŒçš„åœºæ™¯ï¼ˆClaude Sonnet è¿½ç¨³å®šã€Claude Opus è¿½æ€§èƒ½ã€Gemini è¿½é€Ÿåº¦ï¼‰ï¼Œç”¨æˆ·ä¼šæ ¹æ®å…·ä½“éœ€æ±‚åˆ‡æ¢ã€‚")

    # Analysis 4: Emerging trends
    post_lines.append("")
    post_lines.append("4ï¸âƒ£ æ–°å…´è¶‹åŠ¿")
    step_models = [m for m in all_models if 'Step' in m['name']]
    if step_models:
        post_lines.append("âš¡ StepFun ç³»åˆ—å´›èµ·ï¼š")
        for sm in step_models[:2]:
            post_lines.append(f"â€¢ {sm['name']}ï¼ˆç¬¬{sm['rank']}ä½ï¼‰")
        post_lines.append("åˆ†æžï¼šä¸»æ‰“ã€Œæ™ºèƒ½ä½“ä¼˜å…ˆã€å’Œè¶…å¿«æŽ¨ç†é€Ÿåº¦ï¼Œæ­£åœ¨å¸å¼•ç”¨æˆ·å…³æ³¨ã€‚")

    pony_models = [m for m in all_models if 'Pony' in m['name']]
    if pony_models:
        post_lines.append("")
        post_lines.append("ðŸ´ Pony Alpha çš„å´›èµ·ï¼š")
        for pm in pony_models:
            post_lines.append(f"â€¢ {pm['name']}ï¼ˆç¬¬{pm['rank']}ä½ï¼‰")
        post_lines.append("åˆ†æžï¼šç¤¾åŒºå£ç¢‘åž‹é»‘é©¬ï¼Œæ“…é•¿è§’è‰²æ‰®æ¼”å’Œä»£ç ã€‚ç”¨æˆ·æ­£åœ¨ç–¯ç‹‚æµ‹è¯•å®ƒçš„è¾¹ç•Œï¼Œæ˜¯ç›®å‰çš„æµé‡æ˜Žæ˜Ÿã€‚")

    # Engagement
    post_lines.append("")
    post_lines.append("ðŸ‘‰ è¯„è®ºåŒºå‘Šè¯‰æˆ‘ï¼šä½ çŽ°åœ¨ç”¨å“ªä¸ªå½“ä¸»åŠ›ï¼Ÿ")
    post_lines.append("æˆ‘ä¸‹æœŸåšã€Œçº¢é»‘æ¦œ+è¿ç§»ç†ç”±ã€ã€‚")

    return '\n'.join(post_lines)


def save_results(output_dir, screenshot_path, post_content, leaderboard_data):
    """
    Save screenshot and post content.

    Args:
        output_dir: Output directory
        screenshot_path: Path to screenshot
        post_content: Generated post text
        leaderboard_data: Extracted data

    Returns:
        dict: Paths to saved files
    """
    os.makedirs(output_dir, exist_ok=True)

    date_str = datetime.now().strftime('%Y-%m-%d')

    # Save post content
    post_path = os.path.join(output_dir, f'{date_str}-openrouter-post.md')
    with open(post_path, 'w', encoding='utf-8') as f:
        f.write(post_content)

    # Save screenshot if path provided
    screenshot_dest = None
    if screenshot_path and os.path.exists(screenshot_path):
        screenshot_dest = os.path.join(output_dir, f'{date_str}-openrouter-rankings.jpg')
        # Copy screenshot to output directory
        import shutil
        shutil.copy(screenshot_path, screenshot_dest)

    # Save JSON data
    json_path = os.path.join(output_dir, f'{date_str}-openrouter-data.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(leaderboard_data, f, indent=2, ensure_ascii=False)

    return {
        'post_path': post_path,
        'screenshot_path': screenshot_dest,
        'json_path': json_path
    }


def main():
    """Main function to orchestrate workflow."""
    import argparse
    parser = argparse.ArgumentParser(description='Generate OpenRouter daily post')
    parser.add_argument('--snapshot', help='Browser snapshot text')
    parser.add_argument('--screenshot', help='Screenshot file path')
    parser.add_argument('--output', default='/tmp/openrouter-xiaohongshu', help='Output directory')
    args = parser.parse_args()

    if not args.snapshot:
        print("Error: --snapshot is required", file=sys.stderr)
        sys.exit(1)

    # Read snapshot file
    with open(args.snapshot, 'r', encoding='utf-8') as f:
        snapshot_text = f.read()

    # Extract data
    data = run_fetch_data(snapshot_text)

    # Generate post
    post_content = generate_post_content(data)

    if not post_content:
        print("Error: Failed to generate post content", file=sys.stderr)
        sys.exit(1)

    # Save results
    saved_paths = save_results(args.output, args.screenshot, post_content, data)

    # Print summary
    print(f"âœ… Generated post for {datetime.now().strftime('%Y-%m-%d')}")
    print(f"ðŸ“Š Extracted {len(data['leaderboard'])} models")
    print(f"ðŸ“ Post: {saved_paths['post_path']}")
    if saved_paths['screenshot_path']:
        print(f"ðŸ–¼ï¸  Screenshot: {saved_paths['screenshot_path']}")
    print(f"ðŸ“‹ Data: {saved_paths['json_path']}")

    # Print post preview
    print("\n--- Post Preview ---")
    print(post_content[:800] + "..." if len(post_content) > 800 else post_content)


if __name__ == '__main__':
    main()
